for(i in VAR_NUMERIC){
hist(df[,i],main=i,col="lightblue",xlab=i,freq=F)
}
# EMPTY MODEL
mod1 <- lmer(math ~ 1 + (1 | county),df,REML=T)
summary(mod1)
Anova(mod1, type="III")
mod1_null <- lm(math ~ 1,df) #-- modello nullo
anova(mod1,mod1_null) #-- test del rapporto di verosimiglianza
performance::icc(mod1)
# DISEGNI
par(mfrow=c(1,1))
res <- plot_model(mod1, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Intercept
# Si propone ora un random intercept model con variabili di primo livello "calworks"" e "read" e la loro interazione.
# Si ? visto che il coefficiente intraclasse si dimezza perch? una buona parte della varianza complessiva viene
# spiegata dalla variabili esplicative di primo livello. Tutte le variabili risultano essere significative.
#-- R CODE
mod2 <- lmer(math ~ calworks + read + calworks*read + (1| county),df,REML=F) #-- empty model
summary(mod2)
Anova(mod2, type="III")
performance::icc(mod2)
res <- plot_model(mod2, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Slope
mod3 <- lmer(math ~ calworks + read + calworks*read + (calworks| county),df,REML=T) #-- empty model
summary(mod3)
Anova(mod1, type="III")
performance::icc(mod3)
res <- plot_model(mod3, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_coef = res[[1]]$data[order(res[[1]]$data$estimate),]
data_int  = res[[2]]$data[order(res[[2]]$data$estimate),]
plotCI(1:nrow(data_coef),data_coef$estimate,ui=data_coef$conf.high, li=data_coef$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_coef$estimate),col=2,lwd=3,lty=2)
plotCI(1:nrow(data_int),data_int$estimate,ui=data_int$conf.high, li=data_int$conf.low ,pch=19,scol="red",xlab="Country",ylab="Estimate")
abline(h=mean(data_int$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Slope
mod4 <- lmer(math ~ calworks + read + calworks*read + english + (calworks| county),df,REML=T) #-- empty model
summary(mod3)
summary(mod4)
str(df)
Anova(mod4, type="III")
performance::icc(mod4)
performance::icc(mod3)
res <- plot_model(mod4, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_coef = res[[1]]$data[order(res[[1]]$data$estimate),]
data_int  = res[[2]]$data[order(res[[2]]$data$estimate),]
plotCI(1:nrow(data_coef),data_coef$estimate,ui=data_coef$conf.high, li=data_coef$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_coef$estimate),col=2,lwd=3,lty=2)
plotCI(1:nrow(data_int),data_int$estimate,ui=data_int$conf.high, li=data_int$conf.low ,pch=19,scol="red",xlab="Country",ylab="Estimate")
abline(h=mean(data_int$estimate),col=2,lwd=3,lty=2)
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
library(snakecase)
library(glmmTMB)
# MULTILEVEL 1 - Data set: CAS sCHOOL
# Il data set contiene informazioni sulle performance dei test, sulle caratteristiche delle scuole e sulla situazione
# demografica di 420 studenti nei diversi distretti scolastici della California. Ci sono 14 variabili:
# 1. DISTRICT: codice del distretto
# 2. SCHOOL: nome della scuola
# 3. COUNTRY: nome della contea
# 4. GRADES: metodo di voto utilizzato nella contea
# 5. STUDENTS: totale degli studenti nella scuola
# 6. TEACHERS: totale degli insegnanti a tempo pieno
# 7. CALWORKS: percentuale di studenti che rientrano nel programma pubblico assistenziale CalWorks
# 8. LUNCH: percentuale di studenti che hanno diritto ad una riduzione sul prezzo del pranzo
# 9. COMPUTERS: numero di computer per classe
# 10. EXPENDITURE: spesa per studente
# 11. INCOME: reddito medio del distretto (migliaia di USD)
# 12. ENGLISH: percentuale di studenti per cui l'inglese ? la seconda lingua
# 13. READ: punteggio megio nel test di lettura
# 14. MATH: punteggio megio nel test di matematica
# Variabile dipendente: MATH
# Analisi proposte:
#   1. Statistiche descrittive
#   2. Analisi multilevel
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
data_path <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/4a_Esercitazione - Modello Multilevel/R - Multilevel/Esercizio 1/CASchools.txt"
df <- read.table(data_path, sep=" ", header = T)
head(df)
table(df$grades)
VAR_NUMERIC <- names(df)[6:ncol(df)]
summary(df[,VAR_NUMERIC]) #-- statistiche descrittive
cor(df[,VAR_NUMERIC]) #-- matrice di correlazione
plot(df[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
boxplot(df[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
hist(df[,i],main=i,col="lightblue",xlab=i,freq=F)
}
# EMPTY MODEL
mod1 <- lmer(math ~ 1 + (1 | county),df,REML=T)
summary(mod1)
Anova(mod1, type="III")
mod1_null <- lm(math ~ 1,df) #-- modello nullo
anova(mod1,mod1_null) #-- test del rapporto di verosimiglianza
performance::icc(mod1)
# DISEGNI
par(mfrow=c(1,1))
res <- plot_model(mod1, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Intercept
# Si propone ora un random intercept model con variabili di primo livello "calworks"" e "read" e la loro interazione.
# Si ? visto che il coefficiente intraclasse si dimezza perch? una buona parte della varianza complessiva viene
# spiegata dalla variabili esplicative di primo livello. Tutte le variabili risultano essere significative.
#-- R CODE
mod2 <- lmer(math ~ calworks + read + calworks*read + (1| county),df,REML=F) #-- empty model
summary(mod2)
Anova(mod2, type="III")
performance::icc(mod2)
res <- plot_model(mod2, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_1 =res$data[order(res$data$estimate),]
plotCI(1:nrow(data_1),data_1$estimate,ui=data_1$conf.high, li=data_1$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_1$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Slope
mod3 <- lmer(math ~ calworks + read + calworks*read + (calworks| county),df,REML=T) #-- empty model
summary(mod3)
Anova(mod1, type="III")
performance::icc(mod3)
res <- plot_model(mod3, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_coef = res[[1]]$data[order(res[[1]]$data$estimate),]
data_int  = res[[2]]$data[order(res[[2]]$data$estimate),]
plotCI(1:nrow(data_coef),data_coef$estimate,ui=data_coef$conf.high, li=data_coef$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_coef$estimate),col=2,lwd=3,lty=2)
plotCI(1:nrow(data_int),data_int$estimate,ui=data_int$conf.high, li=data_int$conf.low ,pch=19,scol="red",xlab="Country",ylab="Estimate")
abline(h=mean(data_int$estimate),col=2,lwd=3,lty=2)
# REGRESSIONE MULTILEVEL: Random Slope
mod4 <- lmer(math ~ calworks + read + calworks*read + english + (calworks| county),df,REML=T) #-- empty model
summary(mod3)
summary(mod4)
str(df)
Anova(mod4, type="III")
performance::icc(mod4)
performance::icc(mod3)
res <- plot_model(mod4, type = "re", grid = FALSE, show.values=T,title="T",prnt.plot=F, sort.est ="sort.all" )
data_coef = res[[1]]$data[order(res[[1]]$data$estimate),]
data_int  = res[[2]]$data[order(res[[2]]$data$estimate),]
plotCI(1:nrow(data_coef),data_coef$estimate,ui=data_coef$conf.high, li=data_coef$conf.low ,pch=19,scol="blue",xlab="Country",ylab="Estimate")
abline(h=mean(data_coef$estimate),col=2,lwd=3,lty=2)
plotCI(1:nrow(data_int),data_int$estimate,ui=data_int$conf.high, li=data_int$conf.low ,pch=19,scol="red",xlab="Country",ylab="Estimate")
abline(h=mean(data_int$estimate),col=2,lwd=3,lty=2)
# install.packages("car")
# install.packages("sjstats")
# install.packages("plotrix")
# install.packages("sjPlot")
# install.packages("sjmisc")
# install.packages("lme4")
# install.packages("pander")
# install.packages("car")
# install.packages("olsrr")
# install.packages("systemfit")
# install.packages("het.test")
# install.packages("ppcor")'''
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
#-- White test function
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
path_data <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/3a_Esercitazione - Modelli Multivariati/R 01 - Modelli Multivariati/Esercizio 1/countries.txt"
df <- read.table(path_data, header = TRUE, sep="\t")
head(df)
str(df)
gg <- c("Life.expectancy", "Unemployment","Irrigated", "Under.14", "Literacy.Rate", "ISPs.million")
summary(df[,gg])
cor(df[,gg])
plot(df[,gg], pch=17, cex=0.5)
par(mfrow=c(2,3))
for(i in gg){
boxplot(df[,i], main=i, col="lightgreen")
}
par(mfrow=c(2,3))
for(i in gg){
hist(df[,i], main=i, col="lightgreen", freq = F, ylab = i)
}
# Regressioni Singole
mod1 <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, df)
summary(mod1)
anova(mod1)
#-- R CODE
white.test(mod1, df)
dwtest(mod1)
par(mfrow=c(1,1))
#-- R CODE
plot(mod1,which=2,pch=19)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
plot(hatvalues(mod1),rstudent(mod1),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(h=2,col=2,lty=2,lwd=2)
abline(h=-2,col=2,lty=2,lwd=2)
#-- R CODE
plot(cooks.distance(mod1),pch=19,xlab="Observation Index",ylab="Cook DIstance",type="h")
points(cooks.distance(mod1),pch=19)
abline(h=4/nrow(df),col=2,lty=2,lwd=2)
# Elimino outlier
df$ESTREME <- 1 #-- inserisco una nuova colonna del dataset con obs. estreme
df$ESTREME[c(FIND_EXTREME_OBSERVARION(df$Life.expectancy,2),FIND_EXTREME_OBSERVARION(df$Unemployment,2),FIND_EXTREME_OBSERVARION(df$Irrigated,2),FIND_EXTREME_OBSERVARION(df$Under.14,2),FIND_EXTREME_OBSERVARION(df$Literacy.Rate,2),FIND_EXTREME_OBSERVARION(df$ISPs.million,2))] <- 2
d_noaut <- df[-c(FIND_EXTREME_OBSERVARION(df$Life.expectancy,2),FIND_EXTREME_OBSERVARION(df$Unemployment,2),FIND_EXTREME_OBSERVARION(df$Irrigated,2),FIND_EXTREME_OBSERVARION(df$Under.14,2),FIND_EXTREME_OBSERVARION(df$Literacy.Rate,2),FIND_EXTREME_OBSERVARION(df$ISPs.million,2)),]
head(d_noaut)
str(d_noaut)
mod_x <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
summary(mod_x)
anova(mod_x)
#-- R CODE
white.test(mod_x, d_noaut)
dwtest(mod_x)
par(mfrow=c(1,1))
#-- R CODE
plot(mod_x,which=2,pch=19)
hist(resid(mod_x),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod_x)),col=2,lwd=2)
plot(hatvalues(mod_x),rstudent(mod_x),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(h=2,col=2,lty=2,lwd=2)
abline(h=-2,col=2,lty=2,lwd=2)
plot(cooks.distance(mod_x),pch=19,xlab="Observation Index",ylab="Cook DIstance",type="h")
points(cooks.distance(mod_x),pch=19)
abline(h=4/nrow(d_noaut),col=2,lty=2,lwd=2)
# Regressione seconda variabile
mod2 <- lm(Unemployment ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, df)
summary(mod2)
anova(mod2)
#-- R CODE
white.test(mod1, df)
dwtest(mod2)
par(mfrow=c(1,1))
plot(mod2,which=2,pch=19)
hist(resid(mod2),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod2)),col=2,lwd=2)
# Si osserva anceh in questo caso che qualche outlier che andrebbe eliminato:
#-- R CODE
plot(hatvalues(mod2),rstudent(mod2),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(h=2,col=2,lty=2,lwd=2)
abline(h=-2,col=2,lty=2,lwd=2)
plot(cooks.distance(mod2),pch=19,xlab="Observation Index",ylab="Cook DIstance",type="h")
points(cooks.distance(mod2),pch=19)
abline(h=4/nrow(df),col=2,lty=2,lwd=2)
# REGRESIONE MULTIVARIATA
mod3 <- lm(cbind(Unemployment,Life.expectancy) ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, df)
pcor.test(df$Life.expectancy,df$Unemployment,df[,c("ISPs.million","Irrigated","Under.14","Literacy.Rate")])
summary(mod3)
manova(mod3)
pander(manova(mod3),big.mark=",")
Anova(mod3, type="III")
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
data_path <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/3a_Esercitazione - Modelli Multivariati/R 01 - Modelli Multivariati/Esercizio 1/countries.txt"
df <- read.table(data_path, sep="\t", header = T)
head(df)
str(df)
numeric_var <- c("Life.expectancy","Unemployment","Literacy.Rate","ISPs.million","Irrigated","Under.14")
#################################
#   STATISTICHE DESCRITTIVE
#################################
summary(df[, numeric_var])
cor(df[, numeric_var])
plot(df[, numeric_var], pch=17)
par(mfrow=c(2,3))
for(i in numeric_var){
boxplot(df[,i], col='lightgreen', main=i)
}
par(mfrow=c(2,3))
for(i in numeric_var){
hist(df[,i], col='lightgreen', main=i, xlab=i, freq = F)
}
# Si vuole studiare la dipendenza delle variabili "life_expectancy" e "Unemployment" da "ISPs_million",
# "irrigated", "Under_14", "Literacy_Rate". Si propongono dapprima le statistiche descrittive, a seguire le
# matrici di correlazione tra variabili dipendenti, tra variabili esplicative e tra variabili dipendenti.
#################################
#   PRIMA REGRESSIONE
#################################
mod1 <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, df)
summary(mod1)
anova(mod1)
#-- R CODE
white.test(mod1, df)
bptest(mod1)
dwtest(mod1)
ols_vif_tol(mod1)
ols_eigen_cindex(mod1)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
par(mfrow=c(1,1))
plot(mod1,which=2,pch=19)
# ISTOGRAMMA
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
# OUTLIER
df$ESTREME <- 1
df$ESTREME[9] <- 2
df$ESTREME
d_noaut <- df[-c(9),]
#################################
#   PRIMA REGRESSIONE senza OUTLIER
#################################
mod2 <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
summary(mod2)
anova(mod2)
#-- R CODE
white.test(mod2, df)
bptest(mod2)
dwtest(mod2)
ols_vif_tol(mod2)
ols_eigen_cindex(mod2)
shapiro.test(resid(mod2))
ks.test(resid(mod2),"pnorm")
par(mfrow=c(1,1))
plot(mod2,which=2,pch=19)
# ISTOGRAMMA
hist(resid(mod2),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod2)),col=2,lwd=2)
plot(mod2,which=1,pch=19)
plot(mod2,which=2,pch=19)
plot(mod2,which=3,pch=19)
plot(mod2,which=4,pch=19)
abline(h=2*4/nrow(d_noaut),col=2,lwd=3,lty=2)
plot(mod2,which=5,pch=19)
#################################
#   PRIMA REGRESSIONE senza OUTLIER e senza LITERACY RATE
#################################
mod3 <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14, d_noaut)
summary(mod3)
anova(mod3)
#-- R CODE
white.test(mod3, df)
bptest(mod3)
dwtest(mod3)
ols_vif_tol(mod3)
ols_eigen_cindex(mod3)
shapiro.test(resid(mod3))
ks.test(resid(mod3),"pnorm")
par(mfrow=c(1,1))
plot(mod3,which=2,pch=19)
# ISTOGRAMMA
hist(resid(mod3),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod3)),col=2,lwd=2)
plot(mod3,which=1,pch=19)
plot(mod3,which=2,pch=19)
plot(mod3,which=3,pch=19)
plot(mod3,which=4,pch=19)
abline(h=2*4/nrow(d_noaut),col=2,lwd=3,lty=2)
plot(mod3,which=5,pch=19)
#################################
#   SECONDA REGRESSIONE
#################################
mod4 <- lm(Unemployment ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
summary(mod4)
anova(mod4)
#-- R CODE
white.test(mod4, d_noaut)
bptest(mod4)
dwtest(mod4)
ols_vif_tol(mod4)
ols_eigen_cindex(mod4)
shapiro.test(resid(mod4))
ks.test(resid(mod4),"pnorm")
par(mfrow=c(1,1))
plot(mod4,which=2,pch=19)
plot(mod4,which=1,pch=19)
plot(mod4,which=2,pch=19)
plot(mod4,which=3,pch=19)
plot(mod4,which=4,pch=19)
abline(h=2*4/nrow(d_noaut),col=2,lwd=3,lty=2)
plot(mod4,which=5,pch=19)
#################################
#   PRIMA REGRESSIONE WLS
#################################
mod_red <- lm(resid(mod2)^2 ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
weight <- 1/fitted(mod_red)
mod5 <- lm(Life.expectancy ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut[-which(weight<0),],weights = weight[-which(weight<0)])
summary(mod5)
anova(mod5)
#-- R CODE
white.test(mod5, d_noaut)
bptest(mod5)
dwtest(mod5)
ols_vif_tol(mod5)
ols_eigen_cindex(mod5)
shapiro.test(resid(mod5))
ks.test(resid(mod5),"pnorm")
hist(resid(mod5),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod5)),col=2,lwd=2)
plot(mod5,which=1,pch=19)
plot(mod5,which=2,pch=19)
plot(mod5,which=3,pch=19)
plot(mod5,which=4,pch=19)
abline(h=2*4/nrow(d_noaut),col=2,lwd=3,lty=2)
plot(mod5,which=5,pch=19)
#################################
#   PRIMA REGRESSIONE FGLS exp
#################################
mod_red_exp <- lm(log(resid(mod2)^2) ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
sd_error <- sqrt(exp(fitted(mod_red_exp)))
mod0 <- lm( I(Life.expectancy/sd_error) ~ 0 + I(1/sd_error) + I(ISPs.million/sd_error) + I(Irrigated/sd_error) + I(Under.14/sd_error) + I(Literacy.Rate/sd_error), d_noaut)
summary(mod0)
anova(mod0)
#-- R CODE
white.test(mod0, d_noaut)
bptest(mod0)
dwtest(mod0)
ols_vif_tol(mod0)
ols_eigen_cindex(mod0)
shapiro.test(resid(mod0))
ks.test(resid(mod0),"pnorm")
#################################
#   PRIMA REGRESSIONE MULTIVARI
#################################
mod3 <- lm(cbind(Unemployment,Life.expectancy) ~ ISPs.million + Irrigated + Under.14 + Literacy.Rate, d_noaut)
pcor.test(df$Life.expectancy,df$Unemployment,df[,c("ISPs.million","Irrigated","Under.14","Literacy.Rate")])
summary(mod3)
summary(manova(mod3))
Anova(mod3, type="III")
mod4 <- update(mod3, . ~ . - ISPs.million - Irrigated - Under.14 - Literacy.Rate )
anova(mod3, mod4)
lh.out <- linearHypothesis(mod3, hypothesis.matrix = c("ISPs.million = 0", "Irrigated = 0", "Under.14 = 0","Literacy.Rate=0"))
lh.out
summary(manova(cbind(Life.expectancy, Unemployment) ~ ISPs.million, data = d_noaut))
Anova(lm(cbind(Life.expectancy, Unemployment) ~ ISPs.million, data = d_noaut),type="III")
summary(manova(cbind(Life.expectancy, Unemployment) ~ Irrigated, data = d_noaut))
summary(manova(cbind(Life.expectancy, Unemployment) ~ Under.14, data = d_noaut))
summary(manova(cbind(Life.expectancy, Unemployment) ~ Literacy.Rate, data = d_noaut))
#-- R CODE
summary(manova(cbind(Life.expectancy, Unemployment) ~ Literacy.Rate + ISPs.million, data = d_noaut))
Anova(lm(cbind(Life.expectancy, Unemployment) ~ Literacy.Rate + ISPs.million, data = d_noaut),type="III")
summary(manova(cbind(Life.expectancy, Unemployment) ~ Irrigated + Under.14, data = d_noaut))
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
df[,9]
df[9,]
q()
