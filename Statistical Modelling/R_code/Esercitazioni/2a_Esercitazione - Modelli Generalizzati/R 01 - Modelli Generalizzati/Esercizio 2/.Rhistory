#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Esame Vitta - Statistical Modeling\\esercitazioni\\2a_Esercitazione\\R 01 - Modelli Generalizzati\\Esercizio 3"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\Hartnagel.csv"),sep=";")
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("year","tfr","partic","degrees","fconvict","ftheft","mconvict","mtheft")
#-- print delle prime 6 righe del dataset
head(d)
str(d)
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(3,3))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
mod1 <- lm(ftheft ~ partic + degrees + mtheft, d) #-- stima modello lineare semplice
summary(mod1)
white.test(mod1)
dwtest(mod1)
plot(mod1,which=1,pch=19)
par(mfrow=c(1,1))
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=4,pch=19)
abline(h=2*3/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
#-- R CODE
index <- as.numeric(row.names(mod1$model))
plot(d$year[index],resid(mod1),pch=19,xlab="Year",ylab="Residuo",type="l",col=1,lwd=2)
text(d$year[index],resid(mod1),d$year[index],pos=1,cex=.6)
index <- as.numeric(row.names(mod1$model))
plot(d$year[index],resid(mod1),pch=19,xlab="Year",ylab="Residuo",type="l",col=1,lwd=2)
text(d$year[index],resid(mod1),d$year[index],pos=1,cex=.6)
autocorr <- acf(resid(mod1),main="Autocorrelazion",lwd=2)
data.frame(LAG=autocorr$lag,VALUE=autocorr$acf)[1:5,]
cor(resid(mod1),c(NA,resid(mod1)[1:(length(resid(mod1))-1)]),use="pairwise.complete.obs")
mod1$model
d1 <- data.frame(
mod1$model,
resid=resid(mod1),
resid_l1=c(NA,resid(mod1)[1:(length(resid(mod1))-1)]) #-- residui ritardati
)
mod2 <- lm(resid ~ resid_l1,d1)
#-- R CODE
summary(mod2)
anova(mod2)
#-- R CODE
white.test(mod2)
dwtest(mod2)
mod1$model
resid(mod1)
c(NA,resid(mod1)[1:(length(resid(mod1))-1)])
d1 <- data.frame(
mod1$model,
resid=resid(mod1),
resid_l1=c(NA,resid(mod1)[1:(length(resid(mod1))-1)]) #-- residui ritardati
)
str(d1)
head(d1)
mod2 <- lm(resid ~ resid_l1,d1)
summary(mod2)
#-- R CODE
white.test(mod2)
dwtest(mod2)
d1 <- data.frame(
mod1$model,
resid=resid(mod1)
)
d1
d1$ftheft_l1 <- Lag(d1$ftheft,1)
d1
d1$partic_l1 <- Lag(d1$partic,1)
d1$degrees_l1 <- Lag(d1$degrees,1)
d1$mtheft_l1 <- Lag(d1$mtheft,1)
d1$resid_l1 <- Lag(d1$resid,1)
d1$int_tild <- 1-0.542
d1$ftheft_t <- d1$ftheft-0.542*d1$ftheft_l1
d1$partic_t <- d1$partic-0.542*d1$partic_l1
d1$degrees_t <- d1$degrees-0.542*d1$degrees_l1
d1$mtheft_t <- d1$mtheft-0.542*d1$mtheft_l1
d1$resid_t <- d1$resid-0.542*d1$resid_l1
mod3 <- lm(ftheft_t ~ 0 + int_tild + partic_t + degrees_t + mtheft_t,d1)
summary(mod3)
#-- R CODE
white.test(mod3)
dwtest(mod3)
plot(mod3,which=1,pch=19)
plot(mod3,which=2,pch=19)
plot(mod3,which=3,pch=19)
plot(mod3,which=4,pch=19)
abline(h=2*3/nrow(d),col=2,lwd=3,lty=2)
# # GLS 6 - Data set: QUAKES
#
# INTRODUZIONE
# Il dataset riguarda i terremoti rilevati vicino a Fiji. Le osservazioni rappresentano i movimenti sismici rilevati
# nel 1964 con magnitudo maggiore di 4. Le variabili sono:
# 1. LAT: latitudine
# 2. LONG: longitudine
# 3. DEPTH: profondità
# 4. MAG: magnitudo
# 5. STATIONS: stazione
# Analisi proposte:
# 1. Statistiche descrittive
# 2. Regressione
# 3. Gestione dell'autocorrelazione
install.packages("Hmisc")
install.packages("pander")
install.packages("car")
install.packages("olsrr")
install.packages("systemfit")
install.packages("het.test")
install.packages("lmtest")
#-- R CODE
library(Hmisc)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Esame Vitta - Statistical Modeling\\esercitazioni\\2a_Esercitazione\\R 01 - Modelli Generalizzati\\Esercizio 6"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\QUAKES.txt"),sep=" ")
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("lat","long","depth","mag")
#-- print delle prime 6 righe del dataset
head(d)
str(d)
# STATISTICHE DESCRITTIVE
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(3,3))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
# REGRESSIONE
#-- R CODE
mod1 <- lm(mag ~ stations + depth + long + lat , d) #-- stima modello lineare semplice
summary(mod1)
anova(mod1)
par(mfrow=c(1,1))
#-- R CODE
white.test(mod1)
dwtest(mod1) #-- Durbin-Whatson test
# Le 4 variabili esplicative "stations", "depth", "long", "lat" risultano tutte significative. Il valore dell'R2 è
# molto buono e il modello interpreta bene la variabile dipendente.
# Si verifica ora la multicollinearità delle variabili esplicative.
# Per tutti e 4 i valori l'indice di tolleranza è quasi prossimo a uno e quindi mostra che non esiste collinearità.
# Il condition index perfeziona tale conclusione perché se risulta debolmente dipendente per il quarto auto valore
# mentre il quinto assume valore molto elevato andando a spiegare quota di varianza elevata per l'intercetta e
# la variabile "long".
ols_eigen_cindex(mod1)
ols_vif_tol(mod1)
# Si verifica ora la normalità. Si analizza innanzitutto la distribuzione dei residui e il box plot. L'istogramma si
# sovrappone bene alla curva normale teorica.
# Per ciò che concerne il box plot dei residui si verifica che c'è simmetria intorno alla media. Anche la
# distribuzione cumulata dei residui empirici si sovrappone a quella dei residui della distribuzione teorica
# normale
#
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
#-- R CODE
plot(covratio(mod1),pch=19,ylab="Covratio")
abline(h=1-3*7/nrow(d),lwd=3,col=2,lty=2)
abline(h=1+3*7/nrow(d),lwd=3,col=2,lty=2)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
# I test, in particolare Shapiro-Wilk (vicino a 1 come valore) e Kolmogorov-Smirnov, cadono tutti nella regione
# di accettazione: non respingo l'ipotesi nulla di normalità dei residui.
#-- R CODE
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
text(fitted(mod1),resid(mod1),d$nazione,pos=1,cex=.6)
abline(h=0,lwd=2,lty=2,col=2)
# La rappresentazione grafica dei residui ben lontana da una forma rettangolare e il test di White mostrano con
# chiarezza che l'ipotesi di omoschedasticità degli errori va respinta. Inoltre si vede la presenza di outlier (Stati
# Uniti e Svizzera). Per ciò che concerne la non correlazione degli errori si vede dal test di Durbin-Watson che
# è respinta l'ipotesi di non correlazione dei residui. Per risolvere il problema si propone un metodo di stima FGLS.
#-- R CODE
mod2 <- lm(resid(mod1)^2 ~ urbana + vitamas + vitafem + alfabet, d)
weight <- 1/fitted(mod2)
mod3 <- lm(pil ~ urbana + vitamas + vitafem + alfabet, d,weights=weight)
summary(mod3)
anova(mod3)
#-- R CODE
plot(fitted(mod3),resid(mod3),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
text(fitted(mod3),resid(mod3),d$nazione,pos=1,cex=.6)
abline(h=0,lwd=2,lty=2,col=2)
# Il modello ora fitta in modo rilevante i dati e "vitamas" è significativa.
# Si propone ora un modello basato su stime FGLS con errori espressi in forma esponenziale
#-- R CODE
mod5 <- lm(log(resid(mod1)^2) ~ urbana + vitamas + vitafem + alfabet, d)
sd_error <- sqrt(exp(fitted(mod5)))
mod6 <- lm(I(pil/sd_error) ~ 0 + I(1/sd_error) + I(urbana/sd_error) + I(vitamas/sd_error) + I(vitafem/sd_error) + I(alfabet/sd_error) , d)
summary(mod6)
anova(mod6)
#-- R CODE
white.test(mod6)
dwtest(mod6) #-- Durbin-Watson test
# Il modello ora ha un fitting ancora più elevato che il precedente modello e "vitamas" rimane l'unica variabile
# con parametri significativi a mostrare che il "Pil" è influenzato solo dalla speranza di vita maschile tra le
# variabili esplicative prescelte. I test di White e Durbin Watson mostrano che i residui sono omoschedastici e
# incorrelati.
#-- R CODE
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
text(fitted(mod1),resid(mod1),d$nazione,pos=1,cex=.6)
abline(h=0,lwd=2,lty=2,col=2)
#-- R CODE
library(Hmisc)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Esame Vitta - Statistical Modeling\\esercitazioni\\2a_Esercitazione\\R 01 - Modelli Generalizzati\\Esercizio 6"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\QUAKES.txt"),sep=" ")
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("lat","long","depth","mag")
#-- print delle prime 6 righe del dataset
head(d)
str(d)
# STATISTICHE DESCRITTIVE
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(3,3))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
# REGRESSIONE
#-- R CODE
mod1 <- lm(mag ~ stations + depth + long + lat , d) #-- stima modello lineare semplice
summary(mod1)
anova(mod1)
par(mfrow=c(1,1))
#-- R CODE
white.test(mod1)
dwtest(mod1) #-- Durbin-Whatson test
# Le 4 variabili esplicative "stations", "depth", "long", "lat" risultano tutte significative. Il valore dell'R2 è
# molto buono e il modello interpreta bene la variabile dipendente.
# Si verifica ora la multicollinearità delle variabili esplicative.
# Per tutti e 4 i valori l'indice di tolleranza è quasi prossimo a uno e quindi mostra che non esiste collinearità.
# Il condition index perfeziona tale conclusione perché se risulta debolmente dipendente per il quarto auto valore
# mentre il quinto assume valore molto elevato andando a spiegare quota di varianza elevata per l'intercetta e
# la variabile "long".
ols_eigen_cindex(mod1)
ols_vif_tol(mod1)
# Si verifica ora la normalità. Si analizza innanzitutto la distribuzione dei residui e il box plot. L'istogramma si
# sovrappone bene alla curva normale teorica.
# Per ciò che concerne il box plot dei residui si verifica che c'è simmetria intorno alla media. Anche la
# distribuzione cumulata dei residui empirici si sovrappone a quella dei residui della distribuzione teorica
# normale
#
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
#-- R CODE
plot(covratio(mod1),pch=19,ylab="Covratio")
abline(h=1-3*7/nrow(d),lwd=3,col=2,lty=2)
abline(h=1+3*7/nrow(d),lwd=3,col=2,lty=2)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
# I test, in particolare Shapiro-Wilk (vicino a 1 come valore) e Kolmogorov-Smirnov, cadono tutti nella regione
# di accettazione: non respingo l'ipotesi nulla di normalità dei residui.
#-- R CODE
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
text(fitted(mod1),resid(mod1),d$nazione,pos=1,cex=.6)
abline(h=0,lwd=2,lty=2,col=2)
# La rappresentazione grafica dei residui ben lontana da una forma rettangolare e il test di White mostrano con
# chiarezza che l'ipotesi di omoschedasticità degli errori va respinta. Inoltre si vede la presenza di outlier (Stati
# Uniti e Svizzera). Per ciò che concerne la non correlazione degli errori si vede dal test di Durbin-Watson che
# è respinta l'ipotesi di non correlazione dei residui. Per risolvere il problema si propone un metodo di stima FGLS.
#-- R CODE
library(Hmisc)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Esame Vitta - Statistical Modeling\\esercitazioni\\2a_Esercitazione\\R 01 - Modelli Generalizzati\\Esercizio 6"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\QUAKES.txt"),sep=" ")
head(d)
VAR_NUMERIC <- c("lat","long","depth","mag")
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(2,2))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
mod1 <- lm(mag ~ stations + depth + long + lat , d)
summary(mod1)
par(mfrow=c(1,1))
#-- R CODE
white.test(mod1)
dwtest(mod1) #-- Durbin-Whatson test
ols_eigen_cindex(mod1)
ols_vif_tol(mod1)
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
#-- R CODE
plot(covratio(mod1),pch=19,ylab="Covratio")
abline(h=1-3*4/nrow(d),lwd=3,col=2,lty=2)
abline(h=1+3*4/nrow(d),lwd=3,col=2,lty=2)
plot(covratio(mod1),pch=19,ylab="Covratio")
abline(h=1-3*4/nrow(d),lwd=3,col=2,lty=2)
abline(h=1+3*4/nrow(d),lwd=3,col=2,lty=2)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
#-- R CODE
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
text(fitted(mod1),resid(mod1),d$nazione,pos=1,cex=.6)
abline(h=0,lwd=2,lty=2,col=2)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
#panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
path_data <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/2a_Esercitazione - Modelli Generalizzati/R 01 - Modelli Generalizzati/Esercizio 2/companies.csv"
df <- read.table(path_data, sep=";", header=TRUE)
head(df)
str(df)
gg <- c("assets", "sales", "mark_val", "profits", "cash", "employ")
summary(df[,gg])
cor(df[,gg])
plot(df[,gg], pch=17)
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
boxplot(df[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,3))
for(i in gg){
boxplot(df[,i],main=i,col="lightblue",ylab=i)
}
mod1 <- lm(mark_val ~ assets + sales + profits + cash + employ, df) #-- stima modello lineare semplice
summary(mod1)
anova(mod1)
# Il modello interpreta bene la variabile dipendente (R2 = 0.7394) ma solo "cash" e in parte "employ" hanno
# associato parametri significativi. Si verifica ora omoschedasticit? e incorrelazione.
#-- R CODE
white.test(mod1,df)
dwtest(mod1)
# MULTICOLLINEARITA'
# VIF
ols_vif_tol(mod1)
# CINDEX
ols_eigen_cindex(mod1)
# ENTRAMBI
ols_coll_diag(mod1)
# NORMALITA'
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
par(mfrow=c(1,1))
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(d),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
df[69,]
df[29,]
df[64,]
df[14,]
df[29,]
df[64,]
mod2 <- lm(resid(mod1)^2 ~ assets + sales + profits + cash + employ, df) #-- stima modello lineare semplice
summary(mod2)
anova(mod2)
# Da tale procedimento si calcola il valore della varianza dei residui che si ottiene dai valori previsti della
# regressione dei residui al quadrato rispetto ai regressori. La varianza dei residui sar? la varianza di tali valori previsti
#-- R CODE
var(fitted(mod2))
sd(fitted(mod2))
# Il test Durbin Watson non respinge l'ipotesi di non correlazione fra gli errori.
#-- R CODE
white.test(mod2)
dwtest(mod2)
#-- R CODE
white.test(mod2,df)
mod3 <- lm( I(mark_val/sd_error) ~ 0 + I(1/sd_error) + I(assets/sd_error) + I(sales/sd_error) + I(profits/sd_error) + I(cash/sd_error) + I(employ/sd_error), df)
summary(mod3)
anova(mod3)
white.test(mod3,df)
dwtest(mod3)
weight <- 1/fitted(mod2)
mod4 <- lm(mark_val ~ assets + sales + profits + cash + employ, df[-which(weight<0),],weights = weight[-which(weight<0)])
summary(mod4)
anova(mod4)
# Commentiamo i risultati per modello 3 (mod3). Il modello risulta ancora significativo, anzi il fitting migliora
# (R2=0.8727) e solo "cash" risulta significativa. Inoltre si pu? verificare dal grafico residui-predetti e dai test di White e
# Durbin Watson che gli errori sono  ora omoschedastici e incorrelati.
#-- R CODE
white.test(mod3)
dwtest(mod3)
#-- R CODE
white.test(mod3,df)
mod2 <- lm(log(resid(mod1)^2) ~ assets + sales + profits + cash + employ, d)
sd_error <- sqrt(exp(fitted(mod2)))
mod5 <- lm(I(mark_val/sd_error) ~ 0 + I(1/sd_error) + I(assets/sd_error) + I(sales/sd_error) + I(profits/sd_error) + I(cash/sd_error) + I(employ/sd_error), d)
summary(mod5)
anova(mod5)
#-- R CODE
white.test(mod5)
dwtest(mod5)
mod2 <- lm(log(resid(mod1)^2) ~ assets + sales + profits + cash + employ, df)
sd_error <- sqrt(exp(fitted(mod2)))
mod5 <- lm(I(mark_val/sd_error) ~ 0 + I(1/sd_error) + I(assets/sd_error) + I(sales/sd_error) + I(profits/sd_error) + I(cash/sd_error) + I(employ/sd_error), d)
summary(mod5)
anova(mod5)
#-- R CODE
white.test(mod5,df)
dwtest(mod5)
mod2 <- lm(log(resid(mod1)^2) ~ assets + sales + profits + cash + employ, df)
sd_error <- sqrt(exp(fitted(mod2)))
mod5 <- lm(I(mark_val/sd_error) ~ 0 + I(1/sd_error) + I(assets/sd_error) + I(sales/sd_error) + I(profits/sd_error) + I(cash/sd_error) + I(employ/sd_error), d)
mod5 <- lm(I(mark_val/sd_error) ~ 0 + I(1/sd_error) + I(assets/sd_error) + I(sales/sd_error) + I(profits/sd_error) + I(cash/sd_error) + I(employ/sd_error), df)
summary(mod5)
anova(mod5)
#-- R CODE
white.test(mod5,df)
dwtest(mod5)
