install.packages("car")
install.packages("sjstats")
install.packages("plotrix")
install.packages("sjPlot")
install.packages("sjmisc")
install.packages("lme4")
install.packages("pander")
install.packages("car")
install.packages("olsrr")
install.packages("systemfit")
install.packages("het.test")
install.packages("ppcor")
#-- R CODE
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Corso Bicocca Vittadini\\07_Esercitazioni Vitta\\2a_Esercitazione\\R 02 - Modelli Multivariati\\Esercizio 4"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\cigarette.csv"),sep=";")
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("cpi","pop","packpc","income","tax")
#-- print delle prime 6 righe del dataset
head(d)
d_ca <- d[d$state=="CA",]
names(d_ca) <- paste0(names(d_ca),"_CA")
d_ar <- d[d$state=="AR",]
names(d_ar) <- paste0(names(d_ar),"_AR")
d1 <- cbind(d_ar,d_ca)
d_tx <- d[d$state=="TX",]
names(d_tx) <- paste0(names(d_tx),"_TX")
d2 <- cbind(d_tx,d_ca)
# STATISTICHE DESCRITTIVE
# Come variabili dipendenti si usa "bmr" e "Ebmr"; come variabili esplicative si usa "wt", "ht", "Cvit."
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
hist(d[,i],main=i,col="lightblue",xlab=i,freq=F)
}
# REGRESSIONE 1
# L'obiettivo dell'analisi sarà quello di spiegare la variabile "packpc" tramite i regressori "cpi", "pop", "income"
# e "tax". L'analisi in questione si svolgerà su base regionale considerando due stati: Arkansas e California.
#-- R CODE
mod1_AR <- lm(packpc_AR ~ cpi_AR + pop_AR + income_AR + tax_AR, d1)
summary(mod1_AR)
anova(mod1_AR)
# Il modello spiega molto bene la variabile dipendente packpc (R2 = 0.95), ma le uniche variabili significative
# sono "cpi" ad un livello alpha = 0.01, "income" (alpha = 0.005) e "tax" alpha= 0.01. Vediamo ora cosa accade in California.
# REGRESSIONE 2
#-- R CODE
mod1_CA <- lm(packpc_CA ~ cpi_CA + pop_CA + income_CA + tax_CA, d1)
summary(mod1_CA)
anova(mod1_CA)
# Il modello interpreta quasi perfettamente la variabile dipendente e in questo caso le variabili significative
# sono "cpi", "pop".
# Si ricorda che se si sceglie il metodo OLS la regressione multivariata può essere costruita per ciò che riguarda
# l'ottenimento del fitting e dei parametri sulla base delle regressioni multiple costruite separatamente.
cor(data.frame(resid(mod1_CA),resid(mod1_AR)))
# La correlazione tra i residui delle variabili dipendenti nelle due equazioni che risulta essere 0.5662. Si passa ora
# a un modello in cui le variabili esplicative rimangano identiche in entrambe le regressioni e vi è correlazione
# fra gli stessi individui nelle diverse equazioni
e1 <- packpc_AR ~ cpi_AR + pop_AR + income_AR + tax_AR
e2 <- packpc_CA ~ cpi_CA + pop_CA + income_CA + tax_CA
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
R1 <- matrix(0,nrow=1,ncol=10)
R1[ 1, 2 ] <- 1
R1[ 1, 10 ] <- -1
linearHypothesis(mod1,R1,test="FT")
R1
R1[ 1, 2 ] <- 1
R1[ 1, 7 ] <- -1
R1
mod1
linearHypothesis(mod1,R1,test="FT") #-- TEST: clp_AR=cpl_CA
R1 <- matrix(0,nrow=1,ncol=10)
R1
R1[ 1, 2 ] <- 1
R1[ 1, 7 ] <- -1
linearHypothesis(mod1,R1,test="FT") #-- TEST: clp_AR=cpl_CA
#-- TEST: clp_AR=cpl_CA
R1 <- matrix(0,nrow=1,ncol=10)
#-- TEST: clp_AR=cpl_CA
R1 <- matrix(0,nrow=1,ncol=10)
R1[ 1, 2 ] <- 1
R1[ 1, 7 ] <- -1
linearHypothesis(mod1,R1,test="FT")
#-- TEST: tax_AR=tax_CA
R2 <- matrix(0,nrow=1,ncol=10)
R2[ 1, 5 ] <- 1
R2[ 1, 10 ] <- -1
pander(linearHypothesis(mod1,R2,test="FT"))
mod1_AR <- lm(packpc_AR ~ cpi_AR + income_AR + tax_AR, d1)
summary(mod1_AR)
anova(mod1_AR)
mod1_CA <- lm(packpc_CA ~ cpi_CA + pop_CA, d1)
summary(mod1_CA)
#-- R CODE
pander(cor(data.frame(resid(mod1_CA),resid(mod1_AR))))
cor(data.frame(resid(mod1_CA),resid(mod1_AR)))
#-- R CODE
e1 <- packpc_AR ~ cpi_AR + income_AR + tax_AR
e2 <- packpc_CA ~ cpi_CA + pop_CA
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
linearHypothesis(mod1,"e1_cpi_AR = -249.217",test="FT")
linearHypothesis(mod1,"e1_tax_AR = -1.43426",test="FT")
linearHypothesis(mod1,"e2_cpi_CA = -67.7451",test="FT")
#-- R CODE
mod1_CA <- lm(packpc_CA ~ income_CA + avgprs_CA, d2)
summary(mod1_CA)
anova(mod1_CA)
mod1_TX <- lm(packpc_TX ~ income_TX + avgprs_TX, d2)
summary(mod1_TX)
#-- R CODE
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
par(mfrow=c(1,1))
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
plot(1:length(d2$packpc_CA),d2$packpc_CA,pch=19,xlab="Observation Index",ylab="packpc")
white.test(mod1_CA),big.mark=",")
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
par(mfrow=c(1,1))
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
plot(1:length(d2$packpc_CA),d2$packpc_CA,pch=19,xlab="Observation Index",ylab="packpc")
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
plot(mod1_CA,which=2,pch=19)
hist(resid(mod1_CA),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_CA)),col=2,lwd=2)
# I grafici indicano che i residui sono omoschedastici mentre il valore del test di Durbin-Watson mostra che
# l’ipotesi di non correlazione è da accettare.
# Sulla normalità si osservano problemi: c’è uno scostamento abbastanza netto della distribuzione empirica da
# quella teorica. Anche in questo caso necessiterebbe una opportuna correzione. Si consideri ora la seconda
# equazione.
#-- R CODE
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
plot(1:length(d2$packpc_CA),d2$packpc_CA,pch=19,xlab="Observation Index",ylab="packpc")
white.test(mod1_TX)
dwtest(mod1_TX)
bptest(mod1_TX)
whites.htest(mod1_TX)
model1 <- VAR(d2, p =1)
white.test(mod1_TX)
dwtest(mod1_TX)
#-- R CODE
plot(mod1_TX,which=2,pch=19)
hist(resid(mod1_TX),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_TX)),col=2,lwd=2)
#-- R CODE
e1 <- packpc_CA ~ income_CA + avgprs_CA
e2 <- packpc_TX ~ income_TX + avgprs_TX
sistema <- list(e1=e1,e2=e2)
mod3 <- systemfit(sistema,"SUR",data=d2)
summary(mod3)
#-- R CODE
plot(fitted(mod3)[,1],resid(mod3)[,1],pch=19,xlab="Predicted",ylab="Residual",main="CA")
text(fitted(mod3)[,1],resid(mod3)[,1],d2$year_TX,pos=1,cex=0.7)
mod3
dwtest(mod3[[1]][[1]])
#-- R CODE
plot(fitted(mod3)[,2],resid(mod3)[,2],pch=19,xlab="Predicted",ylab="Residual",main="TX")
text(fitted(mod3)[,2],resid(mod3)[,2],d2$year_TX,pos=1,cex=0.7)
dwtest(mod3[[1]][[2]])
#-- R CODE
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
#-- R CODE
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
plot(mod1_CA,which=2,pch=19)
mod1_CA <- lm(packpc_CA ~ income_CA, d2)
summary(mod1_CA)
anova(mod1_CA)
mod1_TX <- lm(packpc_TX ~ avgprs_TX, d2)
summary(mod1_TX)
anova(mod1_TX)
# I modelli offrono entrambi un fitting molto elevato e le variabili esplicative hanno entrambe per la prima volta
# una significatività legata a un p-value pari a inferiore a 0.0001 e hanno un legame negativo e più rilevante che
# nel modello precedente sulle rispettiva variabili dipendenti. Verifichiamo ora omoschedasticità e incorrelazione
# degli errori.
#-- R CODE
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
#-- R CODE
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
plot(mod1_CA,which=2,pch=19)
hist(resid(mod1_CA),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_CA)),col=2,lwd=2)
#-- R CODE
white.test(mod1_TX)
dwtest(mod1_TX)
#-- R CODE
plot(mod1_TX,which=2,pch=19)
hist(resid(mod1_TX),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_TX)),col=2,lwd=2)
#-- R CODE
e1 <- packpc_CA ~ income_CA
e2 <- packpc_TX ~ avgprs_TX
sistema <- list(e1=e1,e2=e2)
mod4 <- systemfit(sistema,"SUR",data=d2)
summary(mod4)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Corso Bicocca Vittadini\\07_Esercitazioni Vitta\\2a_Esercitazione\\R 02 - Modelli Multivariati\\Esercizio 5"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\Gasoline.csv"),sep=";")
d_au <- d[d$COUNTRY=="AUSTRIA",]
names(d_au) <- paste0(names(d_au),"_AU")
d_be <- d[d$COUNTRY=="BELGIUM",]
names(d_be) <- paste0(names(d_be),"_BE")
d1 <- cbind(d_au,d_be)
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("LGASPCAR_AU","LINCOMEP_AU","LRPMG_AU","LCARPCAP_AU","LGASPCAR_BE","LINCOMEP_BE","LRPMG_BE","LCARPCAP_BE")
#-- print delle prime 6 righe del dataset
head(d1)
d_au <- d[d$COUNTRY=="AUSTRIA",]
names(d_au) <- paste0(names(d_au),"_AU")
d_au
d <- read.csv(paste0(ABSOLUTE_PATH,"\\Gasoline.csv"),sep=";")
d
d_au <- d[d$COUNTRY=="AUSTRIA",]
names(d_au) <- paste0(names(d_au),"_AU")
d_au
d_au <- d[d$COUNTRY=="AUSTRIA",]
d$COUNTRY=="AUSTRIA",
d[d$COUNTRY=="AUSTRIA",]
#-- import dei dati
ABSOLUTE_PATH <- "C:\\Users\\daniele.riggi\\Desktop\\Corso Bicocca Vittadini\\07_Esercitazioni Vitta\\2a_Esercitazione\\R 02 - Modelli Multivariati\\Esercizio 5"
d <- read.csv(paste0(ABSOLUTE_PATH,"\\Gasoline.csv"),sep=";")
d_au <- d[d$COUNTRY=="AUSTRIA",]
names(d_au) <- paste0(names(d_au),"_AU")
d_be <- d[d$COUNTRY=="BELGIUM",]
names(d_be) <- paste0(names(d_be),"_BE")
d1 <- cbind(d_au,d_be)
d1
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("LGASPCAR_AU","LINCOMEP_AU","LRPMG_AU","LCARPCAP_AU","LGASPCAR_BE","LINCOMEP_BE","LRPMG_BE","LCARPCAP_BE")
#-- print delle prime 6 righe del dataset
head(d1)
summary(d1[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d1[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d1[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(3,3))
for(i in VAR_NUMERIC){
boxplot(d1[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(3,3))
for(i in VAR_NUMERIC){
hist(d1[,i],main=i,col="lightblue",xlab=i,freq=F)
}
mod1_BE <- lm(LGASPCAR_BE ~ LCARPCAP_BE + LINCOMEP_BE + LRPMG_BE, d1)
summary(mod1_BE)
anova(mod1_BE)
cor(data.frame(resid(mod1_BE),resid(mod1_AU)))
mod1_AU <- lm(LGASPCAR_AU ~ LCARPCAP_AU + LINCOMEP_AU + LRPMG_AU, d1)
summary(mod1_AU)
anova(mod1_AU)
cor(data.frame(resid(mod1_BE),resid(mod1_AU)))
var(data.frame(resid(mod1_BE),resid(mod1_AU)))
#-- R CODE
plot(fitted(mod1)[,1],resid(mod1)[,1],pch=19,xlab="Predicted",ylab="Residual",main="Austria")
par(mfrow=c(1,1))
plot(fitted(mod1)[,1],resid(mod1)[,1],pch=19,xlab="Predicted",ylab="Residual",main="Austria")
hist(resid(mod1)[,1],col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)[,1]),col=2,lwd=2)
par(mfrow=c(1,1))
plot(fitted(mod1)[,1],resid(mod1)[,1],pch=19,xlab="Predicted",ylab="Residual",main="Austria")
hist(resid(mod1)[,1],col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)[,1]),col=2,lwd=2)
#-- R CODE
e1 <- LGASPCAR_AU ~ LCARPCAP_AU + LINCOMEP_AU + LRPMG_AU
e2 <- LGASPCAR_BE ~ LCARPCAP_BE + LINCOMEP_BE + LRPMG_BE
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
# I modelli interpretano bene le variabili dipendenti, meglio quello relativo al Belgio. Per quanto riguarda
# i singoli parametri i valori sono molto simili a quelli ottenuti con la stima OLS e i parametri significativi
# sono i medesimi. Ciò significa che la correlazione tra individui nella stessa posizione non è elevata come era
# prevedibile visto che gli individui nella stessa posizione non sono gli stessi.
#-- R CODE
par(mfrow=c(1,1))
plot(fitted(mod1)[,1],resid(mod1)[,1],pch=19,xlab="Predicted",ylab="Residual",main="Austria")
hist(resid(mod1)[,1],col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)[,1]),col=2,lwd=2)
white.test(mod1[[1]][[1]])
dwtest(mod1[[1]][[1]])
plot(fitted(mod1)[,2],resid(mod1)[,2],pch=19,xlab="Predicted",ylab="Residual",main="Belgio")
hist(resid(mod1)[,2],col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)[,2]),col=2,lwd=2)
white.test(mod1[[1]][[2]])
dwtest(mod1[[1]][[2]])
linearHypothesis(mod1,"e1_LINCOMEP_AU = e2_LINCOMEP_BE",test="FT")
linearHypothesis(mod1,"e1_LCARPCAP_AU = e2_LCARPCAP_BE",test="FT")
linearHypothesis(mod1,"e1_LRPMG_AU = e2_LRPMG_BE",test="FT")
mod1_BE <- lm(LGASPCAR_BE ~ LCARPCAP_BE + LINCOMEP_BE, d1)
summary(mod1_BE)
#-- R CODE
mod1_BE <- lm(LGASPCAR_BE ~ LCARPCAP_BE + LINCOMEP_BE, d1)
summary(mod1_BE)
anova(mod1_BE)
#-- R CODE
mod1_AU <- lm(LGASPCAR_AU ~ LCARPCAP_AU + LINCOMEP_AU + LRPMG_AU, d1)
summary(mod1_AU)
anova(mod1_AU)
# La correlazione tra valori predetti delle variabile dipendente diminuisce leggermente ma il fitting complessivo
# rimane elevatissimo.
cor(data.frame(resid(mod1_BE),resid(mod1_AU)))
var(data.frame(resid(mod1_BE),resid(mod1_AU)))
#-- R CODE
e1 <- LGASPCAR_AU ~ LCARPCAP_AU + LINCOMEP_AU + LRPMG_AU
e2 <- LGASPCAR_BE ~ LCARPCAP_BE + LINCOMEP_BE
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
linearHypothesis(mod1,"e1_LCARPCAP_AU = -0.5199",test="FT")
linearHypothesis(mod1,"e2_LCARPCAP_BE = -0.6687",test="FT")
