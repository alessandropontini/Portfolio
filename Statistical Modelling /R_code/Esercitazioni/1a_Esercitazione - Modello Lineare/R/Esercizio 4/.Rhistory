library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
data_path <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/1a_Esercitazione - Modello Lineare/R/Esercizio 4/road.txt"
df <- read.table(data_path, header=TRUE, sep=" ")
head(df)
str(df)
deaths
""
gg <- c("deaths", "drivers", "popden", "rural", "temp", "fuel")
summary(df[,gg])
cor(df[,gg])
plot(df[,gg], pch=17, cex=.5)
plot(df[,gg], pch=17)
par(mfrow=c(2,3))
for(i in gg){
boxplot(df[,i], main=i, col="lightgreen")
}
hist(df[,i], main=i, col="lightgreen", freq=F, xlab=i)
for(i in gg){
hist(df[,i], main=i, col="lightgreen", freq=F, xlab=i)
}
for(i in gg){
hist(df[,i], main=i, col="lightgreen", freq=F, xlab=i)
}
for(i in gg){
hist(df[,i], main=i, col="lightgreen", freq=F, xlab=i)
}
par(mfrow=c(2,3))
for(i in gg){
hist(df[,i], main=i, col="lightgreen", freq=F, xlab=i)
}
mod1 <- lm(deaths ~ rural, df)
summary(mod1)
summary(mod1)
anova(mod1)
white.test(mod1, df)
dwtest(mod1)
plot(df$rural, df$deaths, pch=17,xlab="Rural",ylab="Deaths")
text(df$rural, df$deaths, df$country, col=1)
abline(mod1, col=2, lwd=3)
par(mfrow=c(1,1))
plot(df$rural, df$deaths, pch=17,xlab="Rural",ylab="Deaths")
text(df$rural, df$deaths, df$country, col=1)
abline(mod1, col=2, lwd=3)
par(mfrow=c(1,1))
plot(df$rural, df$deaths, pch=19,xlab="Rural",ylab="Deaths")
text(df$rural, df$deaths, df$country, col=1)
abline(mod1, col=2, lwd=3)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(mod1, which=1)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(mod1, which=1, pch=19)
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(mod1, which=1, pch=19)
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
plot(mod1, which=2, pch=19)
plot(mod1, which=3, pch=19)
plot(mod1, which=4, pch=19)
plot(mod1, which=1, pch=19)
plot(mod1, which=5, pch=19)
plot(mod1, which=4, pch=19)
plot(mod1, which=4, pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
# COOK DISTANCE 2 VERSIONI
plot(cooks.distance(mod1),pch=19,xlab="Observation Index",ylab="Cook DIstance",type="h")
points(cooks.distance(mod1),pch=19)
abline(h=4/nrow(df),col=2,lty=2,lwd=2)
plot(mod1, which=4, pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
plot(mod1, which=4, pch=19)
points(plot(mod1),pch=19)
plot(mod1, which=4, pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
plot(hatvalues(mod1),rstudent(mod1),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(v=0.04,col=2,lty=2,lwd=2)
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
plot(mod1, which=1, pch=19)
plot(mod1, which=2, pch=19)
plot(mod1, which=3, pch=19)
plot(mod1, which=5, pch=19)
plot(mod1, which=6, pch=19)
plot(mod1, which=7, pch=19)
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
text(df$country, col=1)
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
text(mod1, col=1)
text(fitted(mod1), col=1)
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
text(fitted(mod1), col=1)
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
# RESIDUI STUDENTIZZATI
plot(fitted(mod1),rstudent(mod1),pch=19,xlab="Predicted",ylab="Student - Residual")
abline(h=-2,col=2,lty=2,lwd=2)
abline(h=2,col=2,lty=2,lwd=2)
plot(hatvalues(mod1),rstudent(mod1),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(v=0.04,col=2,lty=2,lwd=2)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(df$rural, df$deaths, pch=19,xlab="Rural",ylab="Deaths")
text(df$rural, df$deaths, df$country, col=1)
abline(mod1, col=2, lwd=3)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(fitted(mod1),df$deaths,pch=19,xlab="Predicted",ylab="Deaths")
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residual")
plot(mod1, which=1, pch=19)
plot(mod1, which=1, pch=19)
plot(mod1,which=2,pch=19)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
plot(mod1,which=5,pch=19)
library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
ABSOLUTE_PATH <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/3a_Esercitazione -Modelli Multivariati SURE/R 02 - Modelli Sure/Esercizio 4/Cigarette.csv"
d <- read.table(ABSOLUTE_PATH, sep=" ", header = TRUE)
str(d)
d <- read.table(ABSOLUTE_PATH, sep=";", header = TRUE)
str(d)
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- c("cpi","pop","packpc","income","tax")
#-- print delle prime 6 righe del dataset
head(d)
d_ca <- d[d$state=="CA",]
names(d_ca) <- paste0(names(d_ca),"_CA")
str(d_ca)
d_ar <- d[d$state=="AR",]
names(d_ar) <- paste0(names(d_ar),"_AR")
d1 <- cbind(d_ar,d_ca)
d_tx <- d[d$state=="TX",]
names(d_tx) <- paste0(names(d_tx),"_TX")
d2 <- cbind(d_tx,d_ca)
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,3))
for(i in VAR_NUMERIC){
hist(d[,i],main=i,col="lightblue",xlab=i,freq=F)
}
mod1_AR <- lm(packpc_AR ~ cpi_AR + pop_AR + income_AR + tax_AR, d1)
summary(mod1_AR)
anova(mod1_AR)
mod1_CA <- lm(packpc_CA ~ cpi_CA + pop_CA + income_CA + tax_CA, d1)
summary(mod1_CA)
anova(mod1_CA)
cor(data.frame(resid(mod1_CA),resid(mod1_AR)))
e1 <- packpc_AR ~ cpi_AR + pop_AR + income_AR + tax_AR
e2 <- packpc_CA ~ cpi_CA + pop_CA + income_CA + tax_CA
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
R1 <- matrix(0,nrow=1,ncol=10)
R1[ 1, 2 ] <- 1
R1[ 1, 10 ] <- -1
linearHypothesis(mod1,R1,test="FT")
linearHypothesis(mod1,R1,test="FT")
#-- TEST: clp_AR=cpl_CA
R1 <- matrix(0,nrow=1,ncol=10)
R1[ 1, 2 ] <- 1
R1[ 1, 7 ] <- -1
linearHypothesis(mod1,R1,test="FT")
R2 <- matrix(0,nrow=1,ncol=10)
R2[ 1, 5 ] <- 1
R2[ 1, 10 ] <- -1
linearHypothesis(mod1,R2,test="FT")
#-- R CODE
mod1_AR <- lm(packpc_AR ~ cpi_AR + income_AR + tax_AR, d1)
summary(mod1_AR)
anova(mod1_AR)
#-- R CODE
mod1_CA <- lm(packpc_CA ~ cpi_CA + pop_CA, d1)
summary(mod1_CA)
anova(mod1_CA)
#-- R CODE
cor(data.frame(resid(mod1_CA),resid(mod1_AR)))
#-- R CODE
e1 <- packpc_AR ~ cpi_AR + income_AR + tax_AR
e2 <- packpc_CA ~ cpi_CA + pop_CA
sistema <- list(e1=e1,e2=e2)
mod1 <- systemfit(sistema,"SUR",data=d1)
summary(mod1)
#-- R CODE
linearHypothesis(mod1,"e1_cpi_AR = -249.217",test="FT")
linearHypothesis(mod1,"e1_tax_AR = -1.43426",test="FT")
linearHypothesis(mod1,"e2_cpi_CA = -67.7451",test="FT")
#-- R CODE
mod1_CA <- lm(packpc_CA ~ income_CA + avgprs_CA, d2)
summary(mod1_CA)
anova(mod1_CA)
mod1_TX <- lm(packpc_TX ~ income_TX + avgprs_TX, d2)
summary(mod1_TX)
anova(mod1_TX)
#-- R CODE
par(mfrow=c(1,1))
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
plot((d2$year_CA),d2$packpc_CA,pch=19,xlab="Observation Index",ylab="packpc")
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
plot(mod1_CA,which=2,pch=19)
hist(resid(mod1_CA),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_CA)),col=2,lwd=2)
#-- R CODE
plot(fitted(mod1_TX),resid(mod1_TX),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_TX),resid(mod1_TX),d2$year_TX,pos=1,cex=0.7)
plot(d2$year_TX,d2$packpc_TX,pch=19,xlab="Observation Index",ylab="packpc")
white.test(mod1_TX)
dwtest(mod1_TX)
#-- R CODE
plot(mod1_TX,which=2,pch=19)
hist(resid(mod1_TX),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_TX)),col=2,lwd=2)
#-- R CODE
e1 <- packpc_CA ~ income_CA + avgprs_CA
e2 <- packpc_TX ~ income_TX + avgprs_TX
sistema <- list(e1=e1,e2=e2)
mod3 <- systemfit(sistema,"SUR",data=d2)
summary(mod3)
#-- R CODE
plot(fitted(mod3)[,1],resid(mod3)[,1],pch=19,xlab="Predicted",ylab="Residual",main="CA")
text(fitted(mod3)[,1],resid(mod3)[,1],d2$year_TX,pos=1,cex=0.7)
#-- R CODE
white.test(mod3[[1]][[1]])
dwtest(mod3[[1]][[1]])
#-- R CODE
plot(fitted(mod3)[,2],resid(mod3)[,2],pch=19,xlab="Predicted",ylab="Residual",main="TX")
text(fitted(mod3)[,2],resid(mod3)[,2],d2$year_TX,pos=1,cex=0.7)
white.test(mod3[[1]][[2]])
dwtest(mod3[[1]][[2]])
mod1_CA <- lm(packpc_CA ~ income_CA, d2)
summary(mod1_CA)
anova(mod1_CA)
mod1_TX <- lm(packpc_TX ~ avgprs_TX, d2)
summary(mod1_TX)
anova(mod1_TX)
#-- R CODE
plot(fitted(mod1_CA),resid(mod1_CA),pch=19,xlab="Predicted",ylab="Residual")
text(fitted(mod1_CA),resid(mod1_CA),d2$year_TX,pos=1,cex=0.7)
#-- R CODE
white.test(mod1_CA)
dwtest(mod1_CA)
#-- R CODE
plot(mod1_CA,which=2,pch=19)
hist(resid(mod1_CA),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_CA)),col=2,lwd=2)
#-- R CODE
white.test(mod1_TX)
dwtest(mod1_TX)
#-- R CODE
plot(mod1_TX,which=2,pch=19)
hist(resid(mod1_TX),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1_TX)),col=2,lwd=2)
#-- R CODE
e1 <- packpc_CA ~ income_CA
e2 <- packpc_TX ~ avgprs_TX
sistema <- list(e1=e1,e2=e2)
mod4 <- systemfit(sistema,"SUR",data=d2)
summary(mod4)
# I valori dei parametri non cambiano quasi per niente. Viene respinta invece l'ipotesi che i parametri relativi a
# I valori dei parametri non cambiano quasi per niente. Viene respinta invece l'ipotesi che i parametri relativi a
# "income" e "avgprs" rispettivamente della prima e seconda equazione siano identici.
# I valori dei parametri non cambiano quasi per niente. Viene respinta invece l'ipotesi che i parametri relativi a
# "income" e "avgprs" rispettivamente della prima e seconda equazione siano identici.
# I valori dei parametri non cambiano quasi per niente. Viene respinta invece l'ipotesi che i parametri relativi a
# "income" e "avgprs" rispettivamente della prima e seconda equazione siano identici.
white.test(mod1_TX)
dwtest(mod1_TX)
#-- R CODE
plot(mod1_TX,which=2,pch=19)
hist(resid(mod1_TX),col="lightblue",freq=F,xlab="Resid",main="")
# LINEAR 5 - Data set: CPUs
# # INTRODUZIONE
#Il data set contiene performance di misura e caratteristiche di 209 CPUs. Le variabili sono le seguenti:
# 1. NAME: produttore del modello
# 2. SYCT: cycle time in nanosecondi
# 3. MMIN: minimim main memory in KB
# 4. MMAX: maximum main memory in KB
# 5. CACH: cache size in KB
# 6. CHMIN: minimum number of channels
# 7. CHMAX: maximum number of channels
# 8. PERF: performance della CPU comparata con il modello IBM 370/158-3
# 9. ESTPERF: stima della performance
#VAriabile target =perf
# Analisi proposte:
#   1. Statistiche descrittive
#   2. Regressione lineare
installed.packages("pander")
install.packages("car")
install.packages("olsrr")
install.packages("systemfit")
install.packages("het.test")
install.packages("lmtest")
install.packages("olsrr")
#-- R CODE
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(lmtest)
library(olsrr)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data=d){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
#-- import dei dati
#-- import dei dati
ABSOLUTE_PATH <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/1a_Esercitazione - Modello Lineare/R/Esercizio 6/cpus.txt"
d <- read.table(ABSOLUTE_PATH, header=TRUE, sep=" ")
#-- print delle prime 6 righe del dataset
head(d)
#-- vettore di variabili numeriche presenti nei dati
VAR_NUMERIC <- names(d)[3:ncol(d)]
summary(d[,VAR_NUMERIC]) #-- statistiche descrittive
cor(d[,VAR_NUMERIC]) #-- matrice di correlazione
plot(d[,VAR_NUMERIC],pch=19,cex=.5) #-- scatter plot multivariato
par(mfrow=c(2,4))
for(i in VAR_NUMERIC){
boxplot(d[,i],main=i,col="lightblue",ylab=i)
}
par(mfrow=c(2,4))
for(i in VAR_NUMERIC){
hist(d[,i],main=i,col="lightblue",xlab=i,freq=F)
}
mod1 <- lm(perf ~ syct + mmin + mmax + cach + chmin + chmax + estperf, d)
summary(mod1)
summary(mod1)
anova(mod1)
white.test(mod1) #-- White test (per dettagli ?bptest)
dwtest(mod1)
ols_vif_tol(mod1)
ols_eigen_cindex(mod1)
mod1 <- lm(perf ~ syct + mmin + mmax + cach + chmin + chmax, d)
summary(mod1)
summary(mod1)
anova(mod1)
white.test(mod1) #-- White test (per dettagli ?bptest)
dwtest(mod1)
ols_vif_tol(mod1)
ols_eigen_cindex(mod1)
par(mfrow=c(1,1))
plot(mod1,which=2,pch=19)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
