library(car)
library(sjstats)
library(plotrix)
library(sjPlot)
library(sjmisc)
library(lme4)
library(pander)
library(car)
library(olsrr)
library(systemfit)
library(het.test)
library(ppcor)
panderOptions('knitr.auto.asis', FALSE)
#-- White test function
white.test <- function(lmod,data){
u2 <- lmod$residuals^2
y <- fitted(lmod)
Ru2 <- summary(lm(u2 ~ y + I(y^2)))$r.squared
LM <- nrow(data)*Ru2
p.value <- 1-pchisq(LM, 2)
data.frame("Test statistic"=LM,"P value"=p.value)
}
#-- funzione per ottenere osservazioni outlier univariate
FIND_EXTREME_OBSERVARION <- function(x,sd_factor=2){
which(x>mean(x)+sd_factor*sd(x) | x<mean(x)-sd_factor*sd(x))
}
data_path <- "/Volumes/HDD_Ale/Statistical Modelling/Esercitazioni/1a_Esercitazione - Modello Lineare/R/Esercizio 1/car.test.txt"
df <- read.table(data_path, sep = " ", header = TRUE)
head(df)
str(df)
gg <- c("Price", "Mileage", "Weight", "Disp.", "HP")
summary(df[,gg])
cor(df[,gg])
plot(df[,gg], pch=17)
par(mfrow=c(2,3))
for(i in gg){
boxplot(df[,gg], main = i, col="lightgreen")
}
for(i in gg){
boxplot(df[,i], main = i, col="lightgreen")
}
par(mfrow=c(2,3))
for(i in gg){
boxplot(df[,i], main = i, col="lightgreen")
}
par(mfrow=c(2,3))
for(i in gg){
hist(df[,i], main = i, col="lightgreen", xlab=i)
}
par(mfrow=c(2,3))
for(i in gg){
hist(df[,i], main = i, col="lightgreen", xlab=i, freq=F)
}
df$ESTREME <- 1 #-- inserisco una nuova colonna del dataset con obs. estreme
df$ESTREME[c(FIND_EXTREME_OBSERVARION(df$Price,2),FIND_EXTREME_OBSERVARION(df$Disp.,2),FIND_EXTREME_OBSERVARION(df$Mileage,2),FIND_EXTREME_OBSERVARION(df$Weight,2),FIND_EXTREME_OBSERVARION(df$HP,2))] <- 2
d_noaut <- df[-c(FIND_EXTREME_OBSERVARION(df$Price,2),FIND_EXTREME_OBSERVARION(df$Disp.,2),FIND_EXTREME_OBSERVARION(df$Mileage,2),FIND_EXTREME_OBSERVARION(df$Weight,2),FIND_EXTREME_OBSERVARION(df$HP,2))]
d_noaut
str(d_noaut)
mod1 <- lm(Price ~ Mileage+Weight+Disp.+HP, df)
summary(mod1)
anova(mod1)
white.test(mod1, df)
dwtest(mod1)
ols_vif_tol(mod1)
ols_eigen_cindex(mod1)
ols_coll_diag(mod1)
X <- df[-df$Price, -df$model, -df$Country, -df$Type, -df$ESTREME]
X <- df[-c(df$Price), -c(df$model), -c(df$Country), -c(df$Type), -c(df$ESTREME)]
gg_x <- c("Mileage", "Weight", "Disp.", "HP")
X <- df[gg_x]
imcdiag(x = X, y = Price)
library(mctest)
install.packages(mctest)
install.packages("mctest")
library(mctest)
imcdiag(x = X, y = Price)
Price <- df[gg_y]
gg_y <- c("Price")
Price <- df[gg_y]
imcdiag(x = X, y = Price)
ols_coll_diag(mod1)
library(ppcor)
pcor(X, method = "pearson")
str(df)
str(d_noaut)
df$ESTREME <- 1 #-- inserisco una nuova colonna del dataset con obs. estreme
df$ESTREME[c(FIND_EXTREME_OBSERVARION(df$Price,2),FIND_EXTREME_OBSERVARION(df$Disp.,2),FIND_EXTREME_OBSERVARION(df$Mileage,2),FIND_EXTREME_OBSERVARION(df$Weight,2),FIND_EXTREME_OBSERVARION(df$HP,2))] <- 2
d_noaut <- df[-c(FIND_EXTREME_OBSERVARION(df$Price,2),FIND_EXTREME_OBSERVARION(df$Disp.,2),FIND_EXTREME_OBSERVARION(df$Mileage,2),FIND_EXTREME_OBSERVARION(df$Weight,2),FIND_EXTREME_OBSERVARION(df$HP,2)),]
str(d_noaut)
omcdiag(X,Price)
omcdiag(X,Price)
imcdiag(x = X, y = Price)
pcor(X, method = "pearson")
ols_eigen_cindex(mod1)
# MULTICOLLINEARITA'
ols_vif_tol(mod1)
par(mfrow=c(1,1))
plot(mod1,which=2,pch=19)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
shapiro.test(resid(mod1))
ks.test(resid(mod1),"pnorm")
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
abline(h=0,lwd=2,lty=2,col=2)
# La rappresentazione grafica dei residui ben lontana da una forma rettangolare e il test di White mostrano con
# chiarezza che l'ipotesi di omoschedasticita' degli errori va respinta.
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
abline(h=0,lwd=2,lty=2,col=2)
# ETEROSCHEDASTICITA'
white.test(mod1, df)
plot(mod1, which=1)
plot(mod1, which=1)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
abline(h=0,lwd=2,lty=2,col=2)
plot(mod1, which=1)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
abline(h=0,lwd=2,lty=2,col=2
abline(h=0,lwd=2,lty=2,col=2)
plot(fitted(mod1),resid(mod1),pch=19,xlab="Predicted",ylab="Residuo",type="p",col=1,lwd=2)
abline(h=0,lwd=2,lty=2,col=2)
# OPPURE QUESTO
plot(mod1, which=1)
plot(hatvalues(mod1),rstudent(mod1),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(v=0.04,col=2,lty=2,lwd=2)
plot(mod1, which=2)
plot(mod1, which=3)
plot(mod1, which=4)
plot(mod1, which=5)
plot(mod1, which=7)
plot(mod1, which=6)
plot(mod1, which=6)
plot(hatvalues(mod1),rstudent(mod1),pch=19,xlab="Leverage",ylab="Student - Residual")
abline(v=0.04,col=2,lty=2,lwd=2)
plot(cooks.distance(mod1),pch=19,xlab="Observation Index",ylab="Cook DIstance",type="h")
points(cooks.distance(mod1),pch=19)
abline(h=4/nrow(df),col=2,lty=2,lwd=2)
# OPPURE
plot(mod1, which=4)
plot(mod1, which=4)
abline(h=4/nrow(df),col=2,lty=2,lwd=2)
plot(mod1,which=1,pch=19)
plot(mod1,which=2,pch=19)
plot(mod1,which=3,pch=19)
plot(mod1,which=4,pch=19)
abline(h=2*4/nrow(df),col=2,lwd=3,lty=2)
plot(mod1,which=5,pch=19)
par(mfrow=c(2,3))
plot(mod1)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
par(mfrow=c(1,1))
plot(mod1,which=2,pch=19)
hist(resid(mod1),col="lightblue",freq=F,xlab="Resid",main="")
lines(density(resid(mod1)),col=2,lwd=2)
